# SwinMR + MriWizard: Vendor-Agnostic MRI Reconstruction

A production-ready deep learning system for MRI acceleration and enhancement that works directly with clinical DICOM images. This project integrates the SwinMR architecture (Swin Transformer for Fast MRI) with the MriWizard k-space simulation framework to enable training on realistic degraded MRI data.

## ğŸ¯ Key Features

- **Vendor-Agnostic**: Works directly with DICOM files from any scanner manufacturer
- **Hybrid Data Loading**: Supports NPY (fast path), DICOM, PNG, and JPG formats with automatic caching
- **Realistic K-space Simulation**: 5 undersampling patterns + Gaussian noise + optional artifacts
- **On-the-fly Degradation**: Different degradations each epoch for robust training
- **Modular Configuration**: Separate, composable configs for training and degradation
- **Production-Ready**: Comprehensive validation, logging, checkpointing, and early stopping

## ğŸ“Š Supported Degradation Patterns

### Undersampling Patterns
1. **Random Undersampling**: Probabilistic k-space line retention
2. **Uniform Undersampling**: Every R-th line with center preservation
3. **Partial Fourier**: Asymmetric k-space acquisition
4. **K-max Undersampling**: Central box cropping (all directions)
5. **Elliptical Undersampling**: Radial masking

### Additional Artifacts (Optional)
- **Gaussian Noise**: Complex k-space noise
- **Motion Artifacts**: Rigid body motion simulation
- **Ghosting**: N/2 ghosting artifacts
- **Spike Noise**: RF interference
- **Gibbs Ringing**: High-frequency truncation

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone or navigate to the project
cd swinmr_mriwizard

# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Your Data

#### Option A: Use NPY Files (Recommended for Speed)

Convert DICOM to NPY format:

```bash
python scripts/convert_dicom_to_npy.py \
    --input-dir /path/to/dicom/files \
    --output-dir ./data/train_npy \
    --recursive
```

#### Option B: Use DICOM Directly

The dataloader will automatically convert and cache DICOM files on first load.

Organize your data:
```
data/
â”œâ”€â”€ train_npy/      # Training images
â”‚   â”œâ”€â”€ image_001.npy
â”‚   â”œâ”€â”€ image_002.npy
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val_npy/        # Validation images
â”‚   â””â”€â”€ ...
â””â”€â”€ test_npy/       # Test images
    â””â”€â”€ ...
```

### 3. Validate Setup

Before training, validate that everything is configured correctly:

```bash
python scripts/validate_setup.py --config configs/train_config.json
```

This checks:
- âœ“ Configuration files load correctly
- âœ“ Degradation pipeline builds successfully
- âœ“ Dataloader works with your data
- âœ“ Model initializes properly
- âœ“ Forward pass and loss computation work

### 4. Visualize Degradations

See what degradations look like on your data:

```bash
python scripts/visualize_degradations.py \
    --degradation-config configs/degradation_all.json \
    --image data/train_npy/sample.npy \
    --output degradation_preview.png \
    --num-samples 3
```

### 5. Train

Start training:

```bash
python training/train.py --config configs/train_config.json --gpu 0
```

Monitor with TensorBoard:

```bash
tensorboard --logdir results/swinmr_mriwizard_hybrid/logs
```

### 6. Evaluate

Test your trained model:

```bash
python evaluation/test.py \
    --config configs/train_config.json \
    --checkpoint results/swinmr_mriwizard_hybrid/checkpoints/best.pth \
    --save-images
```

## âš™ï¸ Configuration

### Main Training Config (`configs/train_config.json`)

```json
{
  "experiment_name": "swinmr_mriwizard_hybrid",

  "data": {
    "train_dir": "./data/train_npy",
    "val_dir": "./data/val_npy",
    "degradation_config": "./configs/degradation_all.json",  // Reference to degradation config
    "batch_size": 8,
    "patch_size": 256,
    "use_patches": true
  },

  "model": {
    "net_type": "swinir",
    "window_size": 8,
    "depths": [6, 6, 6, 6, 6, 6],
    "embed_dim": 180,
    "num_heads": [6, 6, 6, 6, 6, 6]
  },

  "training": {
    "epochs": 100,
    "loss": {
      "spatial": {"type": "charbonnier", "weight": 1.0},
      "frequency": {"type": "fft_mse", "weight": 0.1},
      "perceptual": {"type": "vgg19", "weight": 0.0025}
    },
    "optimizer": {
      "type": "adam",
      "lr": 2e-4,
      "scheduler": {
        "type": "multistep",
        "milestones": [25000, 50000, 75000],
        "gamma": 0.5
      }
    },
    "early_stopping": {
      "enabled": true,
      "patience": 10,
      "metric": "val_ssim"
    }
  }
}
```

### Degradation Config (`configs/degradation_all.json`)

```json
{
  "name": "comprehensive_degradation",

  "noise": {
    "enabled": true,
    "std_range": [0.005, 0.05],  // Random sampling from this range
    "relative": true,
    "reference": "std"
  },

  "undersampling": {
    "strategy": "one_of",  // Randomly choose ONE pattern per sample
    "patterns": [
      {
        "name": "random",
        "enabled": true,
        "weight": 1.0,  // Sampling weight
        "params": {
          "prob_range": [0.3, 0.7],
          "center_fraction": 0.08
        }
      },
      {
        "name": "uniform",
        "enabled": true,
        "weight": 1.0,
        "params": {
          "R_range": [2, 8],
          "center_fraction": 0.08
        }
      }
      // ... more patterns
    ]
  },

  "artifacts": {
    "motion": {
      "enabled": false,  // Disable optional artifacts
      "probability": 0.3,
      "params": { ... }
    }
  }
}
```

### Customizing Degradations

Create your own degradation config:

```bash
cp configs/degradation_all.json configs/my_degradation.json
# Edit my_degradation.json to your needs
```

Then reference it in your training config:

```json
{
  "data": {
    "degradation_config": "./configs/my_degradation.json"
  }
}
```

**Common Customizations:**

- **Testing Pipeline**: Use `degradation_minimal.json` (single undersampling pattern)
- **Light Degradation**: Reduce `std_range` and use higher `prob_range`/`R_range`
- **Heavy Degradation**: Increase noise, enable artifacts
- **Specific Pattern**: Disable all but one undersampling pattern

## ğŸ“ Project Structure

```
swinmr_mriwizard/
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ train_config.json        # Main training config
â”‚   â”œâ”€â”€ degradation_all.json     # Comprehensive degradation
â”‚   â”œâ”€â”€ degradation_minimal.json # Minimal (for testing)
â”‚   â””â”€â”€ README.md                # Config documentation
â”‚
â”œâ”€â”€ data/                         # Data loading
â”‚   â”œâ”€â”€ dataloader.py            # Hybrid MRI dataset
â”‚   â””â”€â”€ pipeline_builder.py      # Build MriWizard pipeline from config
â”‚
â”œâ”€â”€ models/                       # SwinMR architecture
â”‚   â”œâ”€â”€ model_swinmr.py          # Main model class
â”‚   â”œâ”€â”€ network_swinmr.py        # Swin Transformer network
â”‚   â”œâ”€â”€ basicblock.py            # Building blocks
â”‚   â””â”€â”€ loss.py                  # Loss functions
â”‚
â”œâ”€â”€ training/                     # Training scripts
â”‚   â””â”€â”€ train.py                 # Main training script
â”‚
â”œâ”€â”€ evaluation/                   # Evaluation
â”‚   â””â”€â”€ test.py                  # Model testing
â”‚
â”œâ”€â”€ utils/                        # Utilities
â”‚   â”œâ”€â”€ config_loader.py         # Config loading & validation
â”‚   â”œâ”€â”€ checkpoint.py            # Checkpointing
â”‚   â”œâ”€â”€ logger.py                # Logging setup
â”‚   â””â”€â”€ metrics.py               # PSNR, SSIM, LPIPS
â”‚
â”œâ”€â”€ MriWizard/               # MriWizard library
â”‚   â”œâ”€â”€ core/                    # Core functionality
â”‚   â”œâ”€â”€ io/                      # DICOM/Image loaders
â”‚   â”œâ”€â”€ degrade/                 # Degradation transforms
â”‚   â””â”€â”€ reconstruct/             # FFT reconstruction
â”‚
â”œâ”€â”€ scripts/                      # Helper scripts
â”‚   â”œâ”€â”€ validate_setup.py        # Pre-training validation
â”‚   â”œâ”€â”€ visualize_degradations.py # Visualize degradations
â”‚   â””â”€â”€ convert_dicom_to_npy.py  # Batch DICOM conversion
â”‚
â”œâ”€â”€ results/                      # Output directory
â”‚   â””â”€â”€ <experiment_name>/
â”‚       â”œâ”€â”€ checkpoints/         # Model checkpoints
â”‚       â”œâ”€â”€ logs/                # TensorBoard logs
â”‚       â””â”€â”€ samples/             # Sample outputs
â”‚
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ requirements.txt              # Dependencies
```

## ğŸ“ Training Tips

### 1. Start Small

Use `degradation_minimal.json` to quickly test your pipeline:

```bash
python training/train.py \
    --config configs/train_config.json \
    --data.degradation_config configs/degradation_minimal.json \
    --training.epochs 5
```

### 2. Monitor Training

Watch for:
- **PSNR**: Should increase (target >35 dB for diagnostic quality)
- **SSIM**: Should increase (target >0.90)
- **Loss**: Should decrease steadily

### 3. Adjust Learning Rate

If training is unstable:
```json
"optimizer": {
  "lr": 1e-4  // Reduce from 2e-4
}
```

### 4. Use Early Stopping

Prevent overfitting:
```json
"early_stopping": {
  "enabled": true,
  "patience": 10,
  "metric": "val_ssim"
}
```

### 5. Patch Size

- **Larger patches (320Ã—320)**: Better context, more memory
- **Smaller patches (128Ã—128)**: Faster training, less memory
- **Full images (null)**: Best for validation/testing

## ğŸ“Š Evaluation Metrics

- **PSNR (Peak Signal-to-Noise Ratio)**: Measures pixel-wise accuracy (higher is better)
  - >30 dB: Acceptable
  - >35 dB: Good
  - >40 dB: Excellent

- **SSIM (Structural Similarity Index)**: Measures perceptual quality (higher is better)
  - >0.85: Acceptable
  - >0.90: Good
  - >0.95: Excellent

- **LPIPS (Learned Perceptual Image Patch Similarity)**: Perceptual similarity (lower is better)

## ğŸ”§ Troubleshooting

### Issue: "No valid files found"

**Solution**: Check your data directory path and ensure files have correct extensions (.npy, .dcm, .png, .jpg)

```bash
ls data/train_npy/*.npy  # Should list files
```

### Issue: "CUDA out of memory"

**Solutions**:
1. Reduce batch size: `"batch_size": 4`
2. Reduce patch size: `"patch_size": 128`
3. Use gradient accumulation
4. Use mixed precision training

### Issue: "Loss is NaN"

**Solutions**:
1. Reduce learning rate: `"lr": 1e-4`
2. Enable gradient clipping (already enabled by default)
3. Check your data for NaN values

### Issue: "Training is very slow"

**Solutions**:
1. Pre-convert DICOM to NPY: `scripts/convert_dicom_to_npy.py`
2. Increase `num_workers`: `"num_workers": 8`
3. Use smaller `patch_size` during training

### Issue: "Degradation visualization looks wrong"

**Solution**: Check your degradation config parameters. Use `degradation_minimal.json` as a starting point.

## ğŸš€ Advanced Usage

### Command-Line Config Overrides

Override config parameters from command line:

```bash
python training/train.py \
    --config configs/train_config.json \
    --data.batch_size 16 \
    --training.epochs 50 \
    --training.optimizer.lr 1e-4
```

### Resume Training

Resume from a checkpoint:

```bash
python training/train.py \
    --config configs/train_config.json \
    --resume results/swinmr_mriwizard_hybrid/checkpoints/epoch_50.pth
```

### Multi-GPU Training

Edit config (not fully implemented yet, infrastructure in place):

```json
"system": {
  "gpu_ids": [0, 1, 2, 3],
  "distributed": true
}
```

## ğŸ“š References

1. **SwinMR**: Huang, J., Fang, Y., Wu, Y., et al. (2022). "Swin transformer for fast MRI." *Neurocomputing*, 493, 281-304.

2. **AIRS Medical**: Vendor-agnostic MRI reconstruction methodology

3. **MriWizard**: Custom k-space simulation framework for DICOM-based training

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@article{huang2022swin,
  title={Swin transformer for fast MRI},
  author={Huang, Jiahao and Fang, Yinzhe and Wu, Ying and Wu, Huanjun and Gao, Zhifan and Li, Yang and Del Ser, Javier and Xia, Jun and Yang, Guang},
  journal={Neurocomputing},
  volume={493},
  pages={281--304},
  year={2022},
  publisher={Elsevier}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- [ ] Additional undersampling patterns
- [ ] Multi-coil support (parallel imaging)
- [ ] 3D volume processing
- [ ] Contextual pathway integration (scan parameters)
- [ ] Real-time inference optimization

## ğŸ“„ License

See LICENSE file for details.

## ğŸ’¬ Support

For questions or issues:

1. Run validation: `python scripts/validate_setup.py --config configs/train_config.json`
2. Check configuration documentation: `configs/README.md`
3. Review troubleshooting section above

---

**Version**: 1.0
**Last Updated**: January 2025
**Status**: Production-Ready âœ…
